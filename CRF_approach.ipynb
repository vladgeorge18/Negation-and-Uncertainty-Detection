{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVlNnGw0t3Mx"
      },
      "source": [
        "Sets up the necessary dependencies and language models for using spaCy in Spanish and Catalan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8kZX887QrQo"
      },
      "outputs": [],
      "source": [
        "!pip install -U spacy\n",
        "!python -m spacy download es_core_news_md\n",
        "!python -m spacy download ca_core_news_md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25GxE99vLwrQ"
      },
      "outputs": [],
      "source": [
        "!pip install python-crfsuite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8o7SFMnu4tX"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import json\n",
        "import pycrfsuite as crfs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MPwtHtOu4hs"
      },
      "source": [
        "Parse the JSON train and test files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ALsZWJux2HS"
      },
      "outputs": [],
      "source": [
        "def parse_json(file_path):\n",
        "\n",
        "  # Step 1: Open the file in read mode\n",
        "  try:\n",
        "    with open(file_path, \"r\") as json_file:\n",
        "\n",
        "      # Step 2: Load the JSON data using json.load()\n",
        "      parsed_file = json.load(json_file)\n",
        "  except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {file_path}\")\n",
        "  else:\n",
        "    print(\"JSON data parsed successfully!\")\n",
        "    # Step 3: Access and process the data\n",
        "    # (See examples below based on data structure)\n",
        "  return parsed_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui5rlCHBx4cL",
        "outputId": "990911fb-e8a6-4bf6-f535-06dd9c58e867"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JSON data parsed successfully!\n",
            "JSON data parsed successfully!\n"
          ]
        }
      ],
      "source": [
        "training_set = parse_json(\"./train_data.json\")\n",
        "test_set = parse_json(\"./test_data.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9xZLLFCyBH0",
        "outputId": "f9f886fb-cdab-4a3d-e003-a73c2f59f7fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "254\n"
          ]
        }
      ],
      "source": [
        "print(len(training_set))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will start by downloading a Spanish and Catalan language model that splits the texts in sentences and tags the wrods accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Upon thorough analysis of the data sets, we came accross some inconsistencies regarding tagging. For example, in some instances, the same word containing a \"-\" is being interpreted as two separate words and in other instances as one whole word.\n",
        "\n",
        "One such example would be for the word \"ex-fumador\".\n",
        "\n",
        "This inconsistency is creating errors in the parsing stage, so we will avoid the texts that contain such words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5dtphHaHK_z"
      },
      "outputs": [],
      "source": [
        "skip_list = [16,45,106,116,119,120,163,173,177,179,198,215,216,226,229,230,236,243,248]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyfcOM4RQ3Y0"
      },
      "outputs": [],
      "source": [
        "text_words_info = []\n",
        "nlp = spacy.load('es_core_news_md')  # Load the Spanish language model\n",
        "for i in range(len(training_set)):\n",
        "  if i in skip_list:\n",
        "    continue\n",
        "  text = training_set[i]['data']['text']\n",
        "\n",
        "  # Parse the text\n",
        "  doc = nlp(text)\n",
        "\n",
        "  # Extract sentences\n",
        "  sentences = [sent.text for sent in doc.sents]\n",
        "  print(\"text_number:\", i+1)\n",
        "\n",
        "  # Extract words with start and end positions, lemma, and POS tagging for each word\n",
        "  words_info = [{\"sent_idx\":idx, \"sent\":sent,\"word\":token.text, \"start\":token.idx, \"end\":token.idx + len(token), \"lemma\":token.lemma_, \"pos\":token.pos_,\"tag\":' ',\"prefix\":token.prefix_,\"suffix\":token.suffix_}\n",
        "                for idx,sent in enumerate(doc.sents) for token in sent if not token.is_space and token.text not in [\"*\", \"(\",\",\", \"?\",\",\",\"!\",\":\",\";\",\".\",\"&\",\"\\\",\",\"/\",\"-\"]]\n",
        "  text_words_info.append(words_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZGNimgKyczh"
      },
      "source": [
        "Preprocess the test data in a similar fashion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Si_I6mSAx69q"
      },
      "outputs": [],
      "source": [
        "skip_list_test = [3,13,21]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-L0UuMAxw6OM"
      },
      "outputs": [],
      "source": [
        "text_words_info_test = []\n",
        "nlp = spacy.load('es_core_news_md')  # Load the Spanish language model\n",
        "for i in range(len(test_set)):\n",
        "  if i in skip_list_test:\n",
        "    continue\n",
        "  text = test_set[i]['data']['text']\n",
        "\n",
        "  # Parse the text\n",
        "  doc = nlp(text)\n",
        "\n",
        "  # Extract sentences\n",
        "  sentences = [sent.text for sent in doc.sents]\n",
        "  print(\"text_number:\", i+1)\n",
        "\n",
        "  # Extract words with start and end positions, lemma, and POS tagging for each word\n",
        "  words_info = [{\"sent_idx\":idx, \"sent\":sent,\"word\":token.text, \"start\":token.idx, \"end\":token.idx + len(token), \"lemma\":token.lemma_, \"pos\":token.pos_,\"tag\":' ',\"prefix\":token.prefix_,\"suffix\":token.suffix_}\n",
        "                for idx,sent in enumerate(doc.sents) for token in sent if not token.is_space and token.text not in [\"*\", \"(\",\",\", \"?\",\",\",\"!\",\":\",\";\",\".\",\"&\",\"\\\",\",\"/\",\"-\"]]\n",
        "  text_words_info_test.append(words_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We discarded 8% of the train set and 5% of the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPdAe0sjnBb-",
        "outputId": "94a8ef72-ba20-4d2c-f7cf-e30496e33830"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "235\n"
          ]
        }
      ],
      "source": [
        "print(len(text_words_info))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2DHfZ70z3it",
        "outputId": "ed256fc6-3247-4cad-a474-b69ce9e97b04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "61\n"
          ]
        }
      ],
      "source": [
        "print(len(text_words_info_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXavI-eQ2zW2"
      },
      "source": [
        " Extract and sort annotations labeled as \"NEG\", \"NSCO\", \"UNC\", and \"USCO\" from training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9ewlVOn2192"
      },
      "outputs": [],
      "source": [
        "text_neg = []\n",
        "text_nsco = []\n",
        "text_unc = []\n",
        "text_usco = []\n",
        "for idx,document in enumerate(training_set):\n",
        "  if idx in skip_list:\n",
        "    continue\n",
        "  negations = [result_element['value'] for result_element in document[\"predictions\"][0][\"result\"] if \"NEG\" in result_element[\"value\"][\"labels\"]]\n",
        "  negations = sorted(negations, key=lambda x: x['start'])\n",
        "  nsco = [result_element['value'] for result_element in document[\"predictions\"][0][\"result\"] if \"NSCO\" in result_element[\"value\"][\"labels\"]]\n",
        "  nsco = sorted(nsco, key=lambda x: x['start'])\n",
        "  unc = [result_element['value'] for result_element in document[\"predictions\"][0][\"result\"] if \"UNC\" in result_element[\"value\"][\"labels\"]]\n",
        "  unc = sorted(unc, key=lambda x: x['start'])\n",
        "  usco = [result_element['value'] for result_element in document[\"predictions\"][0][\"result\"] if \"USCO\" in result_element[\"value\"][\"labels\"]]\n",
        "  usco = sorted(usco, key=lambda x: x['start'])\n",
        "  text_neg.append(negations)\n",
        "  text_nsco.append(nsco)\n",
        "  text_unc.append(unc)\n",
        "  text_usco.append(usco)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CucOWU58yZ4m"
      },
      "source": [
        " Extract and sort annotations labeled as \"NEG\", \"NSCO\", \"UNC\", and \"USCO\" from test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GSk3CcEyZYy"
      },
      "outputs": [],
      "source": [
        "text_neg_test = []\n",
        "text_nsco_test = []\n",
        "text_unc_test = []\n",
        "text_usco_test = []\n",
        "for idx,document in enumerate(test_set):\n",
        "  if idx in skip_list_test:\n",
        "    continue\n",
        "  negations = [result_element['value'] for result_element in document[\"predictions\"][0][\"result\"] if \"NEG\" in result_element[\"value\"][\"labels\"]]\n",
        "  negations = sorted(negations, key=lambda x: x['start'])\n",
        "  nsco = [result_element['value'] for result_element in document[\"predictions\"][0][\"result\"] if \"NSCO\" in result_element[\"value\"][\"labels\"]]\n",
        "  nsco = sorted(nsco, key=lambda x: x['start'])\n",
        "  unc = [result_element['value'] for result_element in document[\"predictions\"][0][\"result\"] if \"UNC\" in result_element[\"value\"][\"labels\"]]\n",
        "  unc = sorted(unc, key=lambda x: x['start'])\n",
        "  usco = [result_element['value'] for result_element in document[\"predictions\"][0][\"result\"] if \"USCO\" in result_element[\"value\"][\"labels\"]]\n",
        "  usco = sorted(usco, key=lambda x: x['start'])\n",
        "  text_neg_test.append(negations)\n",
        "  text_nsco_test.append(nsco)\n",
        "  text_unc_test.append(unc)\n",
        "  text_usco_test.append(usco)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDbae-ELV9-L"
      },
      "source": [
        "Tagging words in a document with negation labels (\"B-NEG\", \"I-NEG\", \"E-NEG\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_4Ta4tNaNqu"
      },
      "source": [
        "For \"NEG\" - Train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uVQXnwwdNo4"
      },
      "outputs": [],
      "source": [
        "for negs, words_info in zip(text_neg, text_words_info):\n",
        "  neg_counter=0\n",
        "  words_counter =0\n",
        "  while neg_counter < len(negs):\n",
        "\n",
        "    # Move to the next word if didn't find the beginning of a negation\n",
        "    lst = ['exfumador','exfumadora','ex-fumador','ex-fumadora']\n",
        "    if words_info[words_counter]['word'] in lst:\n",
        "      words_info[words_counter]['tag'] = 'B-NEG'\n",
        "      neg_counter+=1\n",
        "      words_counter+=1\n",
        "      continue\n",
        "    if abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) > 1:\n",
        "      words_counter+=1\n",
        "\n",
        "    # The beginning of a negation is the same as its end\n",
        "    elif abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) <=1 and abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) <=1:\n",
        "      words_info[words_counter]['tag'] = 'B-NEG'\n",
        "      neg_counter+=1\n",
        "      words_counter+=1\n",
        "\n",
        "    # The negation has more than one word\n",
        "    elif abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) <=1 and abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) > 1:\n",
        "      words_info[words_counter]['tag'] = 'B-NEG'\n",
        "      words_counter+=1\n",
        "\n",
        "      # Tag the inside of the negation\n",
        "      while abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) > 1:\n",
        "        words_info[words_counter]['tag'] = 'I-NEG' # comment this for ignoring inside tagging\n",
        "        words_counter+=1\n",
        "\n",
        "      # Tag the end of it\n",
        "      if abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) <= 1:\n",
        "        words_info[words_counter]['tag'] = 'E-NEG'\n",
        "        neg_counter+=1\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jH-1GTC7y_CN"
      },
      "source": [
        "For \"NEG\" - Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dYC5JrJy-lE"
      },
      "outputs": [],
      "source": [
        "for negs, words_info in zip(text_neg_test, text_words_info_test):\n",
        "  neg_counter=0\n",
        "  words_counter =0\n",
        "  while neg_counter < len(negs):\n",
        "\n",
        "    # Move to the next word if didn't find the beginning of a negation\n",
        "    lst = ['exfumador','exfumadora','ex-fumador','ex-fumadora']\n",
        "    if words_info[words_counter]['word'] in lst:\n",
        "      words_info[words_counter]['tag'] = 'B-NEG'\n",
        "      neg_counter+=1\n",
        "      words_counter+=1\n",
        "      continue\n",
        "    if abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) > 1:\n",
        "      words_counter+=1\n",
        "\n",
        "    # The beginning of a negation is the same as its end\n",
        "    elif abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) <=1 and abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) <=1:\n",
        "      words_info[words_counter]['tag'] = 'B-NEG'\n",
        "      neg_counter+=1\n",
        "      words_counter+=1\n",
        "\n",
        "    # The negation has more than one word\n",
        "    elif abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) <=1 and abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) > 1:\n",
        "      words_info[words_counter]['tag'] = 'B-NEG'\n",
        "      words_counter+=1\n",
        "\n",
        "      # Tag the inside of the negation\n",
        "      while abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) > 1:\n",
        "        words_info[words_counter]['tag'] = 'I-NEG' # comment this for ignoring inside tagging\n",
        "        words_counter+=1\n",
        "\n",
        "      # Tag the end of it\n",
        "      if abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) <= 1:\n",
        "        words_info[words_counter]['tag'] = 'E-NEG'\n",
        "        neg_counter+=1\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tagging words in a document with negation labels (\"B-NSCO\", \"I-NSCO\", \"E-NSCO\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZm8j8X5aBt7"
      },
      "source": [
        "For \"NSCO\" - Train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uq9f0XRt5iY4"
      },
      "outputs": [],
      "source": [
        "for negs, words_info in zip(text_nsco, text_words_info):\n",
        "  neg_counter=0\n",
        "  words_counter =0\n",
        "  while neg_counter < len(negs):\n",
        "\n",
        "    #move to the next word if didn't find the beginning of a negation\n",
        "    lst = ['exfumador','exfumadora','ex-fumador','ex-fumadora']\n",
        "    if words_info[words_counter]['word'] in lst:\n",
        "      words_info[words_counter]['tag'] = 'B-NSCO'\n",
        "      neg_counter+=1\n",
        "      words_counter+=1\n",
        "      continue\n",
        "    if abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) > 1:\n",
        "      words_counter+=1\n",
        "\n",
        "    #the beginning of a negation is the same as its end\n",
        "    elif abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) <=1 and abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) <=1:\n",
        "      words_info[words_counter]['tag'] = 'B-NSCO'\n",
        "      neg_counter+=1\n",
        "      words_counter+=1\n",
        "\n",
        "    #the negation has more than one word\n",
        "    elif abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) <=1 and abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) > 1:\n",
        "      words_info[words_counter]['tag'] = 'B-NSCO'\n",
        "      words_counter+=1\n",
        "\n",
        "      #tag the inside of the negation\n",
        "      while abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) > 1:\n",
        "\n",
        "        words_info[words_counter]['tag'] = 'I-NSCO' # comment this for ignoring inside tagging\n",
        "        words_counter+=1\n",
        "\n",
        "      #tag the end of it\n",
        "      if abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) <= 1:\n",
        "        words_info[words_counter]['tag'] = 'E-NSCO'\n",
        "        neg_counter+=1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1djDEzkJ0PXd"
      },
      "source": [
        "For \"NSCO\" - Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oSP-EoJ0OyY"
      },
      "outputs": [],
      "source": [
        "for negs, words_info in zip(text_nsco_test, text_words_info_test):\n",
        "  neg_counter=0\n",
        "  words_counter =0\n",
        "  while neg_counter < len(negs):\n",
        "\n",
        "    #move to the next word if didn't find the beginning of a negation\n",
        "    lst = ['exfumador','exfumadora','ex-fumador','ex-fumadora']\n",
        "    if words_info[words_counter]['word'] in lst:\n",
        "      words_info[words_counter]['tag'] = 'B-NSCO'\n",
        "      neg_counter+=1\n",
        "      words_counter+=1\n",
        "      continue\n",
        "    if abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) > 1:\n",
        "      words_counter+=1\n",
        "\n",
        "    #the beginning of a negation is the same as its end\n",
        "    elif abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) <=1 and abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) <=1:\n",
        "      words_info[words_counter]['tag'] = 'B-NSCO'\n",
        "      neg_counter+=1\n",
        "      words_counter+=1\n",
        "\n",
        "    #the negation has more than one word\n",
        "    elif abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) <=1 and abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) > 1:\n",
        "      words_info[words_counter]['tag'] = 'B-NSCO'\n",
        "      words_counter+=1\n",
        "\n",
        "      #tag the inside of the negation\n",
        "      while abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) > 1:\n",
        "\n",
        "        words_info[words_counter]['tag'] = 'I-NSCO' # comment this for ignoring inside tagging\n",
        "        words_counter+=1\n",
        "\n",
        "      #tag the end of it\n",
        "      if abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) <= 1:\n",
        "        words_info[words_counter]['tag'] = 'E-NSCO'\n",
        "        neg_counter+=1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tagging words in a document with uncertainty labels (\"B-UNC\", \"I-UNC\", \"E-UNC\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZLKxM7ovuT5"
      },
      "source": [
        "For \"UNC\" - Train Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zx_cTMS6vVkI"
      },
      "outputs": [],
      "source": [
        "for negs, words_info in zip(text_unc, text_words_info):\n",
        "  neg_counter=0\n",
        "  words_counter =0\n",
        "  while neg_counter < len(negs):\n",
        "\n",
        "\n",
        "    if abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) > 1:\n",
        "      words_counter+=1\n",
        "\n",
        "    #the beginning of a negation is the same as its end\n",
        "    elif abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) <=1 and abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) <=1:\n",
        "      words_info[words_counter]['tag'] = 'B-UNC'\n",
        "      neg_counter+=1\n",
        "      words_counter+=1\n",
        "\n",
        "    #the negation has more than one word\n",
        "    elif abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) <=1 and abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) > 1:\n",
        "      words_info[words_counter]['tag'] = 'B-UNC'\n",
        "      words_counter+=1\n",
        "\n",
        "      #tag the inside of the negation\n",
        "      while abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) > 1:\n",
        "        words_info[words_counter]['tag'] = 'I-UNC' # comment this for ignoring inside tagging\n",
        "        words_counter+=1\n",
        "\n",
        "      #tag the end of it\n",
        "      if abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) <= 1:\n",
        "        words_info[words_counter]['tag'] = 'E-UNC'\n",
        "        neg_counter+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f55yAY4i2oaI"
      },
      "source": [
        "For \"UNC\" - Train Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZGjsCE72CdB"
      },
      "outputs": [],
      "source": [
        "for negs, words_info in zip(text_unc_test, text_words_info_test):\n",
        "  neg_counter=0\n",
        "  words_counter =0\n",
        "  while neg_counter < len(negs):\n",
        "\n",
        "\n",
        "    if abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) > 1:\n",
        "      words_counter+=1\n",
        "\n",
        "    #the beginning of a negation is the same as its end\n",
        "    elif abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) <=1 and abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) <=1:\n",
        "      words_info[words_counter]['tag'] = 'B-UNC'\n",
        "      neg_counter+=1\n",
        "      words_counter+=1\n",
        "\n",
        "    #the negation has more than one word\n",
        "    elif abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) <=1 and abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) > 1:\n",
        "      words_info[words_counter]['tag'] = 'B-UNC'\n",
        "      words_counter+=1\n",
        "\n",
        "      #tag the inside of the negation\n",
        "      while abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) > 1:\n",
        "        words_info[words_counter]['tag'] = 'I-UNC' # comment this for ignoring inside tagging\n",
        "        words_counter+=1\n",
        "\n",
        "      #tag the end of it\n",
        "      if abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) <= 1:\n",
        "        words_info[words_counter]['tag'] = 'E-UNC'\n",
        "        neg_counter+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tagging words in a document with uncertainty labels (\"B-USCO\", \"I-USCO\", \"E-USCO\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQT-3pJkv0oZ"
      },
      "source": [
        "For \"USCO\" - Train Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcKaqCwvvzaK"
      },
      "outputs": [],
      "source": [
        "for negs, words_info in zip(text_usco, text_words_info):\n",
        "  neg_counter=0\n",
        "  words_counter =0\n",
        "  while neg_counter < len(negs):\n",
        "\n",
        "    if abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) > 1:\n",
        "      words_counter+=1\n",
        "\n",
        "    #the beginning of a negation is the same as its end\n",
        "    elif abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) <=1 and abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) <=1:\n",
        "      words_info[words_counter]['tag'] = 'B-USCO'\n",
        "      neg_counter+=1\n",
        "      words_counter+=1\n",
        "\n",
        "    #the negation has more than one word\n",
        "    elif abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) <=1 and abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) > 1:\n",
        "      words_info[words_counter]['tag'] = 'B-USCO'\n",
        "      words_counter+=1\n",
        "\n",
        "      #tag the inside of the negation\n",
        "      while abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) > 1:\n",
        "        words_info[words_counter]['tag'] = 'I-USCO' # comment this for ignoring inside tagging\n",
        "        words_counter+=1\n",
        "\n",
        "      #tag the end of it\n",
        "      if abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) <= 1:\n",
        "        words_info[words_counter]['tag'] = 'E-USCO'\n",
        "        neg_counter+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UdTIhFh3oV4"
      },
      "source": [
        "For \"USCO\" - Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8c73fbo3lIn"
      },
      "outputs": [],
      "source": [
        "for negs, words_info in zip(text_usco_test, text_words_info_test):\n",
        "  neg_counter=0\n",
        "  words_counter =0\n",
        "  while neg_counter < len(negs):\n",
        "\n",
        "    if abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) > 1:\n",
        "      words_counter+=1\n",
        "\n",
        "    #the beginning of a negation is the same as its end\n",
        "    elif abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) <=1 and abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) <=1:\n",
        "      words_info[words_counter]['tag'] = 'B-USCO'\n",
        "      neg_counter+=1\n",
        "      words_counter+=1\n",
        "\n",
        "    #the negation has more than one word\n",
        "    elif abs(negs[neg_counter]['start'] - words_info[words_counter]['start']) <=1 and abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) > 1:\n",
        "      words_info[words_counter]['tag'] = 'B-USCO'\n",
        "      words_counter+=1\n",
        "\n",
        "      #tag the inside of the negation\n",
        "      while abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) > 1:\n",
        "        words_info[words_counter]['tag'] = 'I-USCO' # comment this for ignoring inside tagging\n",
        "        words_counter+=1\n",
        "\n",
        "      #tag the end of it\n",
        "      if abs(negs[neg_counter]['end'] - words_info[words_counter]['end']) <= 1:\n",
        "        words_info[words_counter]['tag'] = 'E-USCO'\n",
        "        neg_counter+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecvZaSh0HD8v"
      },
      "source": [
        "Tag the word outside of any named entity as 'O' - Train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCHUHEMwg__Z"
      },
      "outputs": [],
      "source": [
        "for text in text_words_info:\n",
        "  for word_info in text:\n",
        "    if word_info['tag']==' ':\n",
        "      word_info['tag'] = 'O'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-IFeIXB4lb_"
      },
      "source": [
        "Tag the word outside of any named entity as 'O' - Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1g1zDYtI4kp5"
      },
      "outputs": [],
      "source": [
        "for text in text_words_info_test:\n",
        "  for word_info in text:\n",
        "    if word_info['tag']==' ':\n",
        "      word_info['tag'] = 'O'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "i0zSl3VTmVet"
      },
      "outputs": [],
      "source": [
        "for word_info in text_words_info[0]:\n",
        "  print(word_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqsKdcuuWKIS"
      },
      "source": [
        " Iterates through each document and groups words into sentences, appending each sentence to `text_sentences`. - Train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-LRDAYPWZtW"
      },
      "outputs": [],
      "source": [
        "text_sentences = []\n",
        "for document in text_words_info:\n",
        "  sentences = []\n",
        "  sentence = []\n",
        "  current_idx = 1\n",
        "  for word in document:\n",
        "    if word['sent_idx'] == current_idx:\n",
        "      sentence.append(word)\n",
        "    else:\n",
        "      sentences.append(sentence)\n",
        "      current_idx += 1\n",
        "      sentence = [word]\n",
        "  text_sentences.append(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvGddEHz79bp"
      },
      "source": [
        " Iterates through each document and groups words into sentences, appending each sentence to `text_sentences_test`. - Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyurVl1Z4uPJ"
      },
      "outputs": [],
      "source": [
        "text_sentences_test = []\n",
        "for document in text_words_info_test:\n",
        "  sentences = []\n",
        "  sentence = []\n",
        "  current_idx = 1\n",
        "  for word in document:\n",
        "    if word['sent_idx'] == current_idx:\n",
        "      sentence.append(word)\n",
        "    else:\n",
        "      sentences.append(sentence)\n",
        "      current_idx += 1\n",
        "      sentence = [word]\n",
        "  text_sentences_test.append(sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP9sig5k8mNK"
      },
      "source": [
        "Flattens `text_sentences` into a single list of sentences - Train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pGZgNA3nXsu"
      },
      "outputs": [],
      "source": [
        "# Compute a list of sentences with every sentence of the text_sentences\n",
        "sentences = []\n",
        "for text in text_sentences:\n",
        "  for sentence in text:\n",
        "    words_info = []\n",
        "    for word_info in sentence:\n",
        "      del word_info['sent_idx']\n",
        "      del word_info['sent']\n",
        "      words_info.append(word_info)\n",
        "    sentences.append(words_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vDqYKxN56qr"
      },
      "source": [
        "Flattens `text_sentences` into a single list of sentences - Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coWXxr1V56J_"
      },
      "outputs": [],
      "source": [
        "# Compute a list of sentences with every sentence of the text_sentences\n",
        "sentences_test = []\n",
        "for text in text_sentences_test:\n",
        "  for sentence in text:\n",
        "    words_info = []\n",
        "    for word_info in sentence:\n",
        "      del word_info['sent_idx']\n",
        "      del word_info['sent']\n",
        "      words_info.append(word_info)\n",
        "    sentences_test.append(words_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr9Ps8mK4Kej"
      },
      "source": [
        "Processes a list of sentences to count the occurrences of different tags for each word. - Train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIegxyE-08qX",
        "outputId": "dfb8e968-25f7-49d2-ce60-a4b04266d73d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total words: 163485\n",
            "\n",
            "B-Tags:\n",
            "  B-NEG:  3877\n",
            "  B-NSCO: 3713\n",
            "  B-UNC:  418\n",
            "  B-USCO: 411\n",
            "\n",
            "I-Tags:\n",
            "  I-NEG:  0\n",
            "  I-NSCO: 5253\n",
            "  I-UNC:  4\n",
            "  I-USCO: 879\n",
            "\n",
            "E-Tags:\n",
            "  E-NEG:  76\n",
            "  E-NSCO: 2511\n",
            "  E-UNC:  198\n",
            "  E-USCO: 319\n",
            "\n",
            "O-Tags: 145826\n"
          ]
        }
      ],
      "source": [
        "total_words = 0\n",
        "bneg = 0\n",
        "bnsco = 0\n",
        "ineg = 0\n",
        "insco = 0\n",
        "eneg = 0\n",
        "ensco = 0\n",
        "bunc = 0\n",
        "busco = 0\n",
        "iunc = 0\n",
        "iusco = 0\n",
        "eunc = 0\n",
        "eusco = 0\n",
        "o = 0\n",
        "\n",
        "for sentence in sentences:\n",
        "  for word in sentence:\n",
        "    total_words += 1\n",
        "    if word['tag'] == 'O':\n",
        "      o += 1\n",
        "    elif word['tag'] == 'B-NEG':\n",
        "      bneg += 1\n",
        "    elif word['tag'] == 'B-NSCO':\n",
        "      bnsco += 1\n",
        "    elif word['tag'] == 'B-UNC':\n",
        "      bunc += 1\n",
        "    elif word['tag'] == 'B-USCO':\n",
        "      busco += 1\n",
        "    elif word['tag'] == 'I-NEG':\n",
        "      ineg += 1\n",
        "    elif word['tag'] == 'I-NSCO':\n",
        "      insco += 1\n",
        "    elif word['tag'] == 'I-UNC':\n",
        "      iunc += 1\n",
        "    elif word['tag'] == 'I-USCO':\n",
        "      iusco += 1\n",
        "    elif word['tag'] == 'E-NEG':\n",
        "      eneg += 1\n",
        "    elif word['tag'] == 'E-NSCO':\n",
        "      ensco += 1\n",
        "    elif word['tag'] == 'E-UNC':\n",
        "      eunc += 1\n",
        "    elif word['tag'] == 'E-USCO':\n",
        "      eusco += 1\n",
        "\n",
        "print(f\"Total words: {total_words}\")\n",
        "\n",
        "print(\"\\nB-Tags:\")\n",
        "print(f\"  B-NEG:  {bneg}\")\n",
        "print(f\"  B-NSCO: {bnsco}\")\n",
        "print(f\"  B-UNC:  {bunc}\")\n",
        "print(f\"  B-USCO: {busco}\")\n",
        "\n",
        "print(\"\\nI-Tags:\")\n",
        "print(f\"  I-NEG:  {ineg}\")\n",
        "print(f\"  I-NSCO: {insco}\")\n",
        "print(f\"  I-UNC:  {iunc}\")\n",
        "print(f\"  I-USCO: {iusco}\")\n",
        "\n",
        "print(\"\\nE-Tags:\")\n",
        "print(f\"  E-NEG:  {eneg}\")\n",
        "print(f\"  E-NSCO: {ensco}\")\n",
        "print(f\"  E-UNC:  {eunc}\")\n",
        "print(f\"  E-USCO: {eusco}\")\n",
        "\n",
        "print(f\"\\nO-Tags: {o}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTH_pvRx6MkX"
      },
      "source": [
        "Processes a list of sentences to count the occurrences of different tags for each word. - Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMI-A2EA6N2D",
        "outputId": "1cfe9920-37d5-475c-dd4b-4d21ad05cbb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total words: 41993\n",
            "\n",
            "B-Tags:\n",
            "  B-NEG:  1019\n",
            "  B-NSCO: 971\n",
            "  B-UNC:  116\n",
            "  B-USCO: 115\n",
            "\n",
            "I-Tags:\n",
            "  I-NEG:  0\n",
            "  I-NSCO: 1304\n",
            "  I-UNC:  3\n",
            "  I-USCO: 251\n",
            "\n",
            "E-Tags:\n",
            "  E-NEG:  18\n",
            "  E-NSCO: 643\n",
            "  E-UNC:  54\n",
            "  E-USCO: 88\n",
            "\n",
            "O-Tags: 37411\n"
          ]
        }
      ],
      "source": [
        "total_words = 0\n",
        "bneg = 0\n",
        "bnsco = 0\n",
        "ineg = 0\n",
        "insco = 0\n",
        "eneg = 0\n",
        "ensco = 0\n",
        "bunc = 0\n",
        "busco = 0\n",
        "iunc = 0\n",
        "iusco = 0\n",
        "eunc = 0\n",
        "eusco = 0\n",
        "o = 0\n",
        "\n",
        "for sentence in sentences_test:\n",
        "  for word in sentence:\n",
        "    total_words += 1\n",
        "    if word['tag'] == 'O':\n",
        "      o += 1\n",
        "    elif word['tag'] == 'B-NEG':\n",
        "      bneg += 1\n",
        "    elif word['tag'] == 'B-NSCO':\n",
        "      bnsco += 1\n",
        "    elif word['tag'] == 'B-UNC':\n",
        "      bunc += 1\n",
        "    elif word['tag'] == 'B-USCO':\n",
        "      busco += 1\n",
        "    elif word['tag'] == 'I-NEG':\n",
        "      ineg += 1\n",
        "    elif word['tag'] == 'I-NSCO':\n",
        "      insco += 1\n",
        "    elif word['tag'] == 'I-UNC':\n",
        "      iunc += 1\n",
        "    elif word['tag'] == 'I-USCO':\n",
        "      iusco += 1\n",
        "    elif word['tag'] == 'E-NEG':\n",
        "      eneg += 1\n",
        "    elif word['tag'] == 'E-NSCO':\n",
        "      ensco += 1\n",
        "    elif word['tag'] == 'E-UNC':\n",
        "      eunc += 1\n",
        "    elif word['tag'] == 'E-USCO':\n",
        "      eusco += 1\n",
        "\n",
        "print(f\"Total words: {total_words}\")\n",
        "\n",
        "print(\"\\nB-Tags:\")\n",
        "print(f\"  B-NEG:  {bneg}\")\n",
        "print(f\"  B-NSCO: {bnsco}\")\n",
        "print(f\"  B-UNC:  {bunc}\")\n",
        "print(f\"  B-USCO: {busco}\")\n",
        "\n",
        "print(\"\\nI-Tags:\")\n",
        "print(f\"  I-NEG:  {ineg}\")\n",
        "print(f\"  I-NSCO: {insco}\")\n",
        "print(f\"  I-UNC:  {iunc}\")\n",
        "print(f\"  I-USCO: {iusco}\")\n",
        "\n",
        "print(\"\\nE-Tags:\")\n",
        "print(f\"  E-NEG:  {eneg}\")\n",
        "print(f\"  E-NSCO: {ensco}\")\n",
        "print(f\"  E-UNC:  {eunc}\")\n",
        "print(f\"  E-USCO: {eusco}\")\n",
        "\n",
        "print(f\"\\nO-Tags: {o}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg94vNl4qTnq"
      },
      "source": [
        "Sentences that have at least one word with a tag different of O and sentences that have just tags with O - Train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNN5HpqdpHLr"
      },
      "outputs": [],
      "source": [
        "parsed_sentences = []\n",
        "O_sentences = []\n",
        "for sentence in sentences:\n",
        "  diff = False\n",
        "  for word in sentence:\n",
        "    if word['tag']!='O':\n",
        "      diff = True\n",
        "      break\n",
        "  if diff:\n",
        "    parsed_sentences.append(sentence)\n",
        "  else:\n",
        "    O_sentences.append(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66AeOfdCrXuP",
        "outputId": "19c68ed1-30c6-48d6-ba1e-abaaadf3934c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3577\n",
            "7573\n"
          ]
        }
      ],
      "source": [
        "print(len(parsed_sentences))\n",
        "print(len(O_sentences))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjrMquQx6lKi"
      },
      "source": [
        "Sentences that have at least one word with a tag different of O and sentences that have just tags with O - Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c04u1v9t6keT"
      },
      "outputs": [],
      "source": [
        "parsed_sentences_test = []\n",
        "O_sentences_test = []\n",
        "for sentence in sentences_test:\n",
        "  diff = False\n",
        "  for word in sentence:\n",
        "    if word['tag']!='O':\n",
        "      diff = True\n",
        "      break\n",
        "  if diff:\n",
        "    parsed_sentences_test.append(sentence)\n",
        "  else:\n",
        "    O_sentences_test.append(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7b_VHKP6uNB",
        "outputId": "1b8c262b-b52c-4593-fc82-eebc8ecb4815"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "971\n",
            "2088\n",
            "3059\n"
          ]
        }
      ],
      "source": [
        "print(len(parsed_sentences_test))\n",
        "print(len(O_sentences_test))\n",
        "print(len(sentences_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63_42u3lh_j0"
      },
      "source": [
        "## Start CRF approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agR9SUDyhiUl"
      },
      "source": [
        "Get CRF features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmDIYbS3-qFR"
      },
      "source": [
        "This function converts a sentence into a list of labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jByxRCeqkqWW"
      },
      "outputs": [],
      "source": [
        "def sent2labels(sent):\n",
        "    return [word['tag'] for word in sent]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VgtWNds_qqr"
      },
      "source": [
        "Generate feature dictionaries for words in a sentence for use in CRF models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GC4q8bMMZPVQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_word_to_crf_features(sentence, i):\n",
        "    word = sentence[i]['word']\n",
        "    lemma = sentence[i]['lemma']\n",
        "    pos = sentence[i]['pos']\n",
        "    suffix = sentence[i]['suffix']\n",
        "\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word.lower()':word.lower(),\n",
        "        'pos': pos,\n",
        "        'lemma': lemma,\n",
        "        'suffix':suffix,\n",
        "        'word.isdigit()':word.isdigit(),\n",
        "\n",
        "    }\n",
        "\n",
        "    # Add features for the previous three words within sentence boundaries\n",
        "    for j in range(1, 4):\n",
        "        if i - j >= 0:\n",
        "            word_prev = sentence[i - j]['word']\n",
        "            pos_prev = sentence[i - j]['pos']\n",
        "            lemma_prev = sentence[i - j]['lemma']\n",
        "            suffix_prev = sentence[i-j]['suffix']\n",
        "            features.update({\n",
        "                f'-{j}:word.lower()': word_prev.lower(),\n",
        "                f'-{j}:pos': pos_prev,\n",
        "                f'-{j}:lemma': lemma_prev,\n",
        "                f'-{j}:suffix':suffix_prev,\n",
        "                f'-{j}:word.isdigit()':word_prev.isdigit(),\n",
        "            })\n",
        "\n",
        "    # Add features for the next three words within sentence boundaries\n",
        "    for j in range(1, 4):\n",
        "        if i + j < len(sentence):\n",
        "            word_next = sentence[i + j]['word']\n",
        "            pos_next = sentence[i + j]['pos']\n",
        "            lemma_next = sentence[i + j]['lemma']\n",
        "            suffix_next = sentence[i+j]['suffix']\n",
        "            features.update({\n",
        "                f'+{j}:word.lower()': word_next.lower(),\n",
        "                f'+{j}:pos': pos_next,\n",
        "                f'+{j}:lemma': lemma_next,\n",
        "                f'+{j}:suffix':suffix_next,\n",
        "                f'+{j}:word.isdigit()':word_next.isdigit(),\n",
        "            })\n",
        "\n",
        "    if i == 0:\n",
        "      features['bos'] = True\n",
        "    else:\n",
        "      features['bos'] = False\n",
        "\n",
        "    if i+1 == len(sentence):\n",
        "      features['eos'] = True\n",
        "    else:\n",
        "      features['eos'] = False\n",
        "\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def get_sent_to_crf_features(sentence):\n",
        "    return [get_word_to_crf_features(sentence, i) for i in range(len(sentence))]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3gGHk5vQRvP"
      },
      "source": [
        "Choose train_sents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdeJp_oOtBJH"
      },
      "outputs": [],
      "source": [
        "train_sents = sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcYH8aRx7GK9"
      },
      "source": [
        "Choose test_sents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKyIPY8R7FHd"
      },
      "outputs": [],
      "source": [
        "test_sents = sentences_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_VbweXsQWzC"
      },
      "source": [
        "Compute X_train and y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYzxrBPy_6CJ"
      },
      "source": [
        "Preparing training data for a CRF model by extracting features and labels from sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_Ls4Hr7hiBL"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train = [get_sent_to_crf_features(s) for s in train_sents]\n",
        "y_train = [sent2labels(s) for s in train_sents]\n",
        "\n",
        "\n",
        "trainer_crf = crfs.Trainer(verbose=False) # Instance a CRF trainer\n",
        "\n",
        "for xseq, yseq in zip(X_train, y_train):\n",
        "    trainer_crf.append(xseq, yseq) # Stack the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oS4Q33uO_iA",
        "outputId": "19225605-c6ad-4ee1-e4cf-1f5895340345"
      },
      "outputs": [],
      "source": [
        "print(X_train[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbtXeuA365Tp"
      },
      "source": [
        "Compute X_test and y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6JuinPN65FI"
      },
      "outputs": [],
      "source": [
        "X_test = [get_sent_to_crf_features(s) for s in test_sents]\n",
        "y_test = [sent2labels(s) for s in test_sents]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KudiYigJQdSr"
      },
      "source": [
        "Set Parameters for CRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cP9JPacpJ58S"
      },
      "outputs": [],
      "source": [
        "trainer_crf.set_params({\n",
        "    'c1': 1.0,   # Coefficient for L1 regularization\n",
        "    'c2': 1e-3,  # Coefficient for L2 regularization\n",
        "    'max_iterations': 100,\n",
        "    'feature.possible_transitions': True\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjMdAXx0QiZp"
      },
      "source": [
        "Train CRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-hZnusjJ800",
        "outputId": "67aae80e-266a-4c8c-ca9a-0a3c0a7916b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<contextlib.closing at 0x7e4c992cd450>"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer_crf.train('npl_ner_crf.crfsuite') # Train the model and save it locally.\n",
        "tagger_crf = crfs.Tagger()\n",
        "tagger_crf.open('npl_ner_crf.crfsuite') # Load the inference API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLj7bfdb78XO"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from itertools import chain\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IxBEhiGAbuT"
      },
      "source": [
        "Generate a classification report for BIO-tagged sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0GXcga87zyw"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "def bio_classification_report(y_true, y_pred):\n",
        "   \n",
        "    lb = LabelBinarizer()\n",
        "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
        "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
        "\n",
        "    tagset = set(lb.classes_) - {'O'}\n",
        "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
        "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
        "\n",
        "    return classification_report(\n",
        "        y_true_combined,\n",
        "        y_pred_combined,\n",
        "        labels = [class_indices[cls] for cls in tagset],\n",
        "        target_names = tagset,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgUOtoarQlmA"
      },
      "source": [
        "Here we generate predictions for the test set using a CRF model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky6wRgnbOtfG",
        "outputId": "beec6dee-542a-4a7d-aba9-7415148ed088"
      },
      "outputs": [],
      "source": [
        "y_pred_crf = [tagger_crf.tag(x) for x in X_test]\n",
        "report_crf = bio_classification_report(y_test, y_pred_crf)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pqwp6FZw7eHt",
        "outputId": "98156f61-134e-48ad-fbab-5701acc33db6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-NEG       0.97      0.96      0.97      1019\n",
            "       E-NEG       0.94      0.89      0.91        18\n",
            "      B-NSCO       0.95      0.92      0.94       971\n",
            "      E-NSCO       0.86      0.86      0.86       643\n",
            "      I-NSCO       0.88      0.88      0.88      1304\n",
            "       B-UNC       0.91      0.71      0.80       116\n",
            "       E-UNC       0.87      0.72      0.79        54\n",
            "       I-UNC       0.00      0.00      0.00         3\n",
            "      B-USCO       0.91      0.72      0.81       115\n",
            "      E-USCO       0.61      0.49      0.54        88\n",
            "      I-USCO       0.69      0.64      0.66       251\n",
            "\n",
            "   micro avg       0.90      0.87      0.89      4582\n",
            "   macro avg       0.78      0.71      0.74      4582\n",
            "weighted avg       0.90      0.87      0.89      4582\n",
            " samples avg       0.10      0.10      0.10      4582\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(report_crf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2eKO8pQ55xE"
      },
      "source": [
        "Calculate metrics for 'NEG', 'NSCO', 'UNC' and 'USCO'  \n",
        "Preprocesse the true and predicted BIO-tagged sequences by removing the 'B-' and 'I-' prefixes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPI-CBt7_RMM"
      },
      "outputs": [],
      "source": [
        "prep_y_test = []\n",
        "prep_y_pred_crf = []\n",
        "for true_sent , pred_sent in zip(y_test,y_pred_crf):\n",
        "  prep_true_sent = []\n",
        "  prep_pred_sent = []\n",
        "  for true_tag, pred_tag in zip(true_sent,pred_sent):\n",
        "\n",
        "    if true_tag!='O':\n",
        "      prep_tag = true_tag[2:]\n",
        "      prep_true_sent.append(prep_tag)\n",
        "    else:\n",
        "      prep_true_sent.append(true_tag)\n",
        "\n",
        "    if pred_tag!='O':\n",
        "      prep_tag = pred_tag[2:]\n",
        "      prep_pred_sent.append(prep_tag)\n",
        "    else:\n",
        "      prep_pred_sent.append(pred_tag)\n",
        "  prep_y_test.append(prep_true_sent)\n",
        "  prep_y_pred_crf.append(prep_pred_sent)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jbk5zJX0BrJq",
        "outputId": "cc7bacbe-a1ad-430b-e2d6-af314910200b"
      },
      "outputs": [],
      "source": [
        "report_crf_2 = bio_classification_report(prep_y_test, prep_y_pred_crf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T8LaSM6CZDw",
        "outputId": "e31c283f-2b9f-4c80-9cd5-8c5f70e4afaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NEG       0.97      0.96      0.96      1037\n",
            "        NSCO       0.92      0.91      0.92      2918\n",
            "         UNC       0.90      0.70      0.79       173\n",
            "        USCO       0.79      0.69      0.73       454\n",
            "\n",
            "   micro avg       0.92      0.89      0.90      4582\n",
            "   macro avg       0.89      0.81      0.85      4582\n",
            "weighted avg       0.92      0.89      0.90      4582\n",
            " samples avg       0.10      0.10      0.10      4582\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(report_crf_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmL3tenGM9kI"
      },
      "source": [
        "Compare results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1hrxg1yHQ1n",
        "outputId": "d84539e3-085d-47fa-f8cb-6b5f003691fc"
      },
      "outputs": [],
      "source": [
        "# Compare result for bad sentences tagging\n",
        "idx = 0\n",
        "count=0\n",
        "for true_sent , pred_sent in zip(y_test,y_pred_crf):\n",
        "  for true_tag, pred_tag in zip(true_sent,pred_sent):\n",
        "    if true_tag != pred_tag:\n",
        "      print(idx)\n",
        "      print(\"True: \",true_sent)\n",
        "      print(\"Pred: \",pred_sent)\n",
        "      print(\"---------------\")\n",
        "      count+=1\n",
        "      break\n",
        "\n",
        "  idx+=1\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AqN31C83gSD"
      },
      "source": [
        "Tagging example True vs Pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "md0sC8wFW0aE",
        "outputId": "0ad0fe53-45dd-4f97-ed8f-aa182fd7aa80"
      },
      "outputs": [],
      "source": [
        "\n",
        "for y_pred_crf_s, test_sents_s in zip(y_pred_crf[412:416],test_sents[412:416]):\n",
        "  sent_true = []\n",
        "  sent_pred = []\n",
        "  for pred_tag, word in zip(y_pred_crf_s, test_sents_s):\n",
        "    sent_true.append((word['word'],word['tag']))\n",
        "    sent_pred.append((word['word'],pred_tag))\n",
        "  print(\"True: \",sent_true)\n",
        "  print(\"Pred: \",sent_pred)\n",
        "  print(\"----------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uOvrcEA0eSI"
      },
      "source": [
        "Calculate Precision, Recall and F1  \n",
        "We calculate the false positives (FP), false negatives (FN), and true positives (TP) for different categories (NEG, UNC, USCO, NSCO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ze9g-5m10V7-"
      },
      "outputs": [],
      "source": [
        "neg_fp = 0\n",
        "neg_fn = 0\n",
        "neg_tp = 0\n",
        "\n",
        "nsco_fp = 0\n",
        "nsco_fn = 0\n",
        "nsco_tp = 0\n",
        "\n",
        "unc_fp = 0\n",
        "unc_fn = 0\n",
        "unc_tp = 0\n",
        "\n",
        "usco_fp = 0\n",
        "usco_fn = 0\n",
        "usco_tp = 0\n",
        "\n",
        "d = {'NEG' : {'FP' : 0, \"FN\" : 0, 'TP' : 0}, 'UNC' : {'FP' : 0, \"FN\" : 0, 'TP' : 0}, 'USCO' : {'FP' : 0, \"FN\" : 0, 'TP' : 0}, 'NSCO' : {'FP' : 0, \"FN\" : 0, 'TP' : 0}}\n",
        "\n",
        "iddd = 0\n",
        "bla = 0\n",
        "fn = 0\n",
        "tp = 0\n",
        "for p_sen, gt_sen in zip(y_pred_crf, y_test):\n",
        "  iddd += 1\n",
        "  for i in range(len(p_sen)):\n",
        "    category = \"\"\n",
        "    # If the prediciton is 'O'\n",
        "    if p_sen[i] == 'O':\n",
        "      if gt_sen[i] == 'O' or gt_sen[i][0] == 'I' or gt_sen[i][0] == 'E':\n",
        "        continue\n",
        "\n",
        "      category = gt_sen[i][2:]\n",
        "\n",
        "      d[category]['FN'] += 1\n",
        "      if category == \"NSCO\":\n",
        "        fn += 1\n",
        "      i += 1\n",
        "\n",
        "      # Go to the end of the tag. This makes sure that for a sequence of\n",
        "      # B-NSCO, I-NSCO, E-NSCO only 1 fn is added\n",
        "      while i < len(p_sen) and gt_sen[i][2:] == category:\n",
        "        i += 1\n",
        "      i -= 1\n",
        "\n",
        "    elif gt_sen[i] == 'O':\n",
        "      category = p_sen[i][2:]\n",
        "      d[category]['FP'] += 1\n",
        "      i += 1\n",
        "      while i < len(p_sen) and p_sen[i][2:] == category:\n",
        "        i += 1\n",
        "      i -= 1\n",
        "\n",
        "    elif p_sen[i][0] == \"B\":\n",
        "      p_category = p_sen[i][2:]\n",
        "      if gt_sen[i] != p_sen[i]:\n",
        "        bla += 1\n",
        "        gt_category = gt_sen[i][2:]\n",
        "        d[p_category]['FP'] += 1\n",
        "        d[gt_category]['FN'] += 1\n",
        "        i += 1\n",
        "        while i < len(p_sen) and (gt_sen[i][2:] == gt_category or p_sen[i][2:] == p_category):\n",
        "          i += 1\n",
        "        i -= 1\n",
        "\n",
        "\n",
        "      elif gt_sen[i] == p_sen[i]:\n",
        "        i += 1\n",
        "        good = True\n",
        "        while i < len(p_sen):\n",
        "          if gt_sen[i][2:] == 'O' and p_sen[i][2:] == 'O':\n",
        "            i -= 1\n",
        "            break\n",
        "          if gt_sen[i][2:] != p_category and p_sen[i][2:] != p_category:\n",
        "            i -= 1\n",
        "            break\n",
        "          if gt_sen[i][2:] == p_category and p_sen[i][2:] == p_category:\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "          good = False\n",
        "          d[p_category]['FN'] += 1\n",
        "          if gt_sen[i][2:] != p_category:\n",
        "            pass\n",
        "          elif p_sen[i][2:] != p_category:\n",
        "            pass\n",
        "          else:\n",
        "            print(f'{gt_sen[i]=} {p_sen[i]=}')\n",
        "         # i-=1\n",
        "          break\n",
        "        if good:\n",
        "          if p_category == \"NSCO\":\n",
        "            tp += 1\n",
        "          d[p_category][\"TP\"] += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKz9KM7x0qrV",
        "outputId": "e5907807-1d24-4234-8c5c-4146e284fbea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NEG: FP 27\n",
            "NEG: FN 43\n",
            "NEG: TP 974\n",
            "UNC: FP 10\n",
            "UNC: FN 37\n",
            "UNC: TP 82\n",
            "USCO: FP 63\n",
            "USCO: FN 61\n",
            "USCO: TP 55\n",
            "NSCO: FP 218\n",
            "NSCO: FN 146\n",
            "NSCO: TP 823\n"
          ]
        }
      ],
      "source": [
        "for tag, metrics in d.items():\n",
        "  for metric, nr in metrics.items():\n",
        "    print(f'{tag}: {metric} {nr}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYXwFAte0rP5",
        "outputId": "c6db0b51-1918-4d60-8e6f-1735d1475e93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: [('NEG', 0.973026973026973), ('UNC', 0.8913043478260869), ('USCO', 0.4661016949152542), ('NSCO', 0.7905859750240154)]\n",
            "Recall: [('NEG', 0.9577187807276303), ('UNC', 0.6890756302521008), ('USCO', 0.47413793103448276), ('NSCO', 0.849329205366357)]\n",
            "F1: [('NEG', 0.9653121902874132), ('UNC', 0.7772511848341233), ('USCO', 0.47008547008547), ('NSCO', 0.8189054726368159)]\n"
          ]
        }
      ],
      "source": [
        "precision = []\n",
        "recall = []\n",
        "f1 = []\n",
        "\n",
        "for tag, metrics in d.items():\n",
        "  p = metrics['TP'] / (metrics['TP'] + metrics['FP'])\n",
        "  precision.append((tag, p))\n",
        "  r = metrics['TP'] / (metrics['TP'] + metrics['FN'])\n",
        "  recall.append((tag, r))\n",
        "  f1.append((tag, (2 * p * r) / (p + r)))\n",
        "\n",
        "print(\"Precision: \" + str(precision))\n",
        "print(\"Recall: \" + str(recall))\n",
        "print(\"F1: \" + str(f1))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
