{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LkOktoy5xRL"
      },
      "source": [
        "training_set = Tot setul de date, este vectorul care contine toate documentele\n",
        "document = Element din training_set. Fiecare document contine \"data\", \"annotations\" si \"predictions\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8V6veP5-ByqK"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2GF2GPXAxXi"
      },
      "source": [
        "Parse Training and Testing data from JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nJJ1HEr2147_"
      },
      "outputs": [],
      "source": [
        "def parse_json(file_path):\n",
        "\n",
        "  # Step 2: Open the file in read mode\n",
        "  try:\n",
        "    with open(file_path, \"r\") as json_file:\n",
        "      # Step 3: Load the JSON data using json.load()\n",
        "      parsed_file = json.load(json_file)\n",
        "  except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {file_path}\")\n",
        "  else:\n",
        "    print(\"JSON data parsed successfully!\")\n",
        "    # Step 4: Access and process the data\n",
        "    # (See examples below based on data structure)\n",
        "  return parsed_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0QPozyd5xRM",
        "outputId": "07f57a46-17cf-4fba-96e5-52b4911d8e1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JSON data parsed successfully!\n",
            "JSON data parsed successfully!\n"
          ]
        }
      ],
      "source": [
        "training_set = parse_json(\"./train_data.json\")\n",
        "testing_set = parse_json(\"./test_data.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8vgfvxL2s5P",
        "outputId": "825e6b3f-a93e-4ae2-bb75-495c6d1fb73f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "254\n",
            "64\n"
          ]
        }
      ],
      "source": [
        "print(len(training_set))\n",
        "print(len(testing_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rDlG9kmj5xRO"
      },
      "outputs": [],
      "source": [
        "predictions = [document[\"predictions\"] for document in training_set]\n",
        "texts = [document[\"data\"][\"text\"] for document in training_set]\n",
        "test_texts = [document[\"data\"][\"text\"] for document in testing_set]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO47cFyb30E-"
      },
      "source": [
        "Extract terms given by CUTEXT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DEnc1hI2-dcN"
      },
      "outputs": [],
      "source": [
        "def extract_terms_from_file(file_path):\n",
        "    terms = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            if line.startswith(\"Term:\"):\n",
        "                term = line.split(\"Term:\")[1].strip()\n",
        "                terms.append(term)\n",
        "    return terms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oiUsBmvlK7BF"
      },
      "outputs": [],
      "source": [
        "def parse_terms(extracted_terms):\n",
        "  new_terms = []\n",
        "  for term in extracted_terms:\n",
        "    if term[0].isalpha() and term[-1].isalpha() and \"**\" not in term and \"(\" not in term and \")\" not in term and len(term)>3:\n",
        "      new_terms.append(term)\n",
        "  return new_terms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Ur92zYTcItiX"
      },
      "outputs": [],
      "source": [
        "file_path = \"./terms_raw.txt\"\n",
        "# Extract terms from the file\n",
        "cutext_terms = extract_terms_from_file(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOcMyguOI351",
        "outputId": "6e91fb16-4e07-4b8f-a9a2-5b583b619ff6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21554\n"
          ]
        }
      ],
      "source": [
        "print(len(cutext_terms))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "kk3JZb87Mt83"
      },
      "outputs": [],
      "source": [
        "cutext_terms = parse_terms(cutext_terms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DKPRePm5xRO"
      },
      "source": [
        "Extract NEG, UNC, NSCO and USCO from Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "CgMZeYPB5xRO"
      },
      "outputs": [],
      "source": [
        "# Gets a list of tuples representing character offsets and returns list of words\n",
        "def get_words(text, offsets):\n",
        "  words = []\n",
        "  for start, end in offsets:\n",
        "    #words.append(text[start:end-1])\n",
        "    #words.append(text[start-1:end])\n",
        "    if text[start-1].isalpha():\n",
        "      s=start-1\n",
        "    else:\n",
        "      s=start\n",
        "    if text[end-1].isalpha():\n",
        "      e=end\n",
        "    else:\n",
        "      e=end-1\n",
        "    words.append(text[s:e])\n",
        "  return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "NNwlbJFT5xRP"
      },
      "outputs": [],
      "source": [
        "# Parses a document and returns 4 lists of tuples representing words\n",
        "def find_cues_and_scopes(document):\n",
        "  neg_postitions_pairs = [(result_element[\"value\"][\"start\"], result_element[\"value\"][\"end\"]) for result_element in document[\"predictions\"][0][\"result\"] if \"NEG\" in result_element[\"value\"][\"labels\"]]\n",
        "  unc_postitions_pairs = [(result_element[\"value\"][\"start\"], result_element[\"value\"][\"end\"]) for result_element in document[\"predictions\"][0][\"result\"] if \"UNC\" in result_element[\"value\"][\"labels\"]]\n",
        "  nsco_postitions_pairs = [(result_element[\"value\"][\"start\"], result_element[\"value\"][\"end\"]) for result_element in document[\"predictions\"][0][\"result\"] if \"NSCO\" in result_element[\"value\"][\"labels\"]]\n",
        "  usco_postitions_pairs = [(result_element[\"value\"][\"start\"], result_element[\"value\"][\"end\"]) for result_element in document[\"predictions\"][0][\"result\"] if \"USCO\" in result_element[\"value\"][\"labels\"]]\n",
        "  neg_words = get_words(document[\"data\"][\"text\"], neg_postitions_pairs)\n",
        "  unc_words = get_words(document[\"data\"][\"text\"], unc_postitions_pairs)\n",
        "  nsco_words = get_words(document[\"data\"][\"text\"], nsco_postitions_pairs)\n",
        "  usco_words = get_words(document[\"data\"][\"text\"], usco_postitions_pairs)\n",
        "  return neg_words, unc_words, nsco_words, usco_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "3KCH-BsM5xRP"
      },
      "outputs": [],
      "source": [
        "NEG = set()\n",
        "UNC = set()\n",
        "NSCO = set()\n",
        "USCO = set()\n",
        "\n",
        "num_nsco = 0\n",
        "num_usco = 0\n",
        "for document in training_set:\n",
        "  neg_words, unc_words, nsco_words, usco_words = find_cues_and_scopes(document)\n",
        "  nsco_words_set = set(nsco_words)\n",
        "  usco_words_set = set(usco_words)\n",
        "  num_nsco += len(nsco_words)\n",
        "  num_usco += len(usco_words)\n",
        "\n",
        "  NEG.update(neg_words)\n",
        "  UNC.update(unc_words)\n",
        "  NSCO.update(nsco_words)\n",
        "  USCO.update(usco_words)\n",
        "\n",
        "# Removing spaces and punctation signs from the start and end of each string\n",
        "NEG = {word.strip(\" ,.!?;)\") for word in NEG}\n",
        "UNC = {word.strip(\" ,.!?);\") for word in UNC}\n",
        "NSCO = {word.strip(\" ,.!?;)\") for word in NSCO}\n",
        "USCO = {word.strip(\" ,.!?);\") for word in USCO}\n",
        "\n",
        "# Remove negation from UNC\n",
        "for word in NEG:\n",
        "  if word in UNC:\n",
        "    UNC.remove(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjomeTlu8oHN"
      },
      "source": [
        "Combine USCO and NSCO in SCOPE_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gtv4WScpWxrl",
        "outputId": "46f88ac2-e300-4d50-a1e2-1173e8eadf21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NEG_UNC words before processing:  3184\n"
          ]
        }
      ],
      "source": [
        "ALL_SCOPES = NSCO.union(USCO)\n",
        "\n",
        "# A set with all individual words from the scopes\n",
        "SCOPE_words = set()         # ['erc', '(29/05/18)', 'ser', 'visibles', 'extratono', 'inicia', 'valor', 'frialdad', 'medicamentoses', 'neoformativo']\n",
        "for scope in ALL_SCOPES:\n",
        "  SCOPE_words.update(scope.split())\n",
        "\n",
        "print(\"NEG_UNC words before processing: \", len(SCOPE_words))\n",
        "\n",
        "# Remove all symbols and numbers from the set\n",
        "SCOPE_words = {word for word in SCOPE_words if word.isalpha()}\n",
        "SCOPE_words = list(SCOPE_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28sA1kjp9D76"
      },
      "source": [
        "Combine SCOPE_words with extracted_terms from CUTEXT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "cTOnXwCaYtMx"
      },
      "outputs": [],
      "source": [
        "extracted_terms = list(set(cutext_terms+SCOPE_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKDyK0dRY929",
        "outputId": "fda7ead0-ba72-40ff-ba1a-1ef146866cb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "19959\n"
          ]
        }
      ],
      "source": [
        "print(len(extracted_terms))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "_vplFWHbEprg"
      },
      "outputs": [],
      "source": [
        "extracted_terms.sort(key=len,reverse=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeXd2xOB_OOE"
      },
      "source": [
        "Prepare REGEX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "TIKVWGYf3fv1"
      },
      "outputs": [],
      "source": [
        "NEG_pattern = \"|\".join(NEG)\n",
        "UNC_pattern = \"|\".join(UNC)\n",
        "#SCOPE pattern with CUTEXT + NSCO+USCO\n",
        "SCOPE_pattern = \"|\".join(extracted_terms)\n",
        "#SCOPE pattern baselie\n",
        "SCOPE_pattern_baseline = \"|\".join(SCOPE_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "id": "cxmKcN5VCYZk"
      },
      "outputs": [],
      "source": [
        "#SCOPE pattern just for CUTEXT\n",
        "SCOPE_pattern_CUTEXT = \"|\".join(cutext_terms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "PgvAtD98vpxh"
      },
      "outputs": [],
      "source": [
        "\n",
        "regex_neg_pos=rf\"\\b({SCOPE_pattern})\\b\\s\\b({NEG_pattern})\\b\"\n",
        "\n",
        "regex_unc_pos=rf\"\\b({SCOPE_pattern})\\b\\s\\b({UNC_pattern})\\b\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clIK5DtE2ZDp"
      },
      "source": [
        "REGEX Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {
        "id": "KZSj1OYg2X0D"
      },
      "outputs": [],
      "source": [
        "regex_neg_pre =rf\"\\b({NEG_pattern})\\b\\s+((?:\\b(?:{SCOPE_pattern_baseline})\\b\\s*){{0,5}})\"\n",
        "regex_unc_pre=rf\"\\b({UNC_pattern})\\b\\s+((?:\\b(?:{SCOPE_pattern_baseline})\\b\\s*){{0,5}})\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy02iJ7Nqz6X"
      },
      "source": [
        "REGEX CUTEXT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "id": "F1bN9VlSqtiv"
      },
      "outputs": [],
      "source": [
        "regex_neg_pre =rf\"\\b({NEG_pattern})\\b\\s+((?:\\b(?:{SCOPE_pattern_CUTEXT})\\b\\s*){{0,5}})\"\n",
        "regex_unc_pre=rf\"\\b({UNC_pattern})\\b\\s+((?:\\b(?:{SCOPE_pattern_CUTEXT})\\b\\s*){{0,5}})\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qylXAB6qp2pN"
      },
      "source": [
        "REGEX1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {
        "id": "ZvOrpfG57VM3"
      },
      "outputs": [],
      "source": [
        "regex_neg_pre =rf\"\\b({NEG_pattern})\\b\\s+((?:\\b(?:{SCOPE_pattern})\\b\\s*){{0,5}})\"\n",
        "regex_unc_pre=rf\"\\b({UNC_pattern})\\b\\s+((?:\\b(?:{SCOPE_pattern})\\b\\s*){{0,5}})\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZTF-Q7dp0AE"
      },
      "source": [
        "REGEX2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {
        "id": "8HpQRAAxLVR-"
      },
      "outputs": [],
      "source": [
        "regex_neg_pre =rf\"\\b({NEG_pattern})\\b\\s*((?:\\b(?:{SCOPE_pattern})\\b\\s*){{0,5}})\"\n",
        "regex_unc_pre=rf\"\\b({UNC_pattern})\\b\\s*((?:\\b(?:{SCOPE_pattern})\\b\\s*){{0,5}})\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "REGEX until the end of the proposition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "regex_neg_pre = rf\"\\b({NEG_pattern})\\b\\s*(.*?)\\.\"\n",
        "regex_unc_pre = rf\"\\b({UNC_pattern})\\b\\s*(.*?)\\.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5piE7K3VqNZ",
        "outputId": "7bc430b3-d83f-4a9f-fa32-de95b00b04fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "324031\n"
          ]
        }
      ],
      "source": [
        "print(len(SCOPE_pattern))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U66u6gH3_aM0"
      },
      "source": [
        "Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "ERlHYxLZvIHG"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "for i in range(len(test_texts)):\n",
        "  dict = {\"NEG\":set(),\"NSCO\":set(),\"UNC\":set(),\"USCO\":set()}\n",
        "\n",
        "  predictions.append(dict)\n",
        "\n",
        "\n",
        "for id, test_text in enumerate(test_texts):\n",
        "  neg_scopes_pre_matches = re.finditer(regex_neg_pre, test_text)\n",
        "  neg_scopes_pos_matches = re.finditer(regex_neg_pos, test_text)\n",
        "  unc_scopes_pre_matches = re.finditer(regex_unc_pre, test_text)\n",
        "  unc_scopes_pos_matches = re.finditer(regex_unc_pos, test_text)\n",
        "\n",
        "  if neg_scopes_pre_matches:\n",
        "    for match in neg_scopes_pre_matches:\n",
        "        #print(\"Whole match:\", match.group(0))\n",
        "        # Get the matched word and its starting/ending positions\n",
        "        matched_word = match.group(1)\n",
        "        start_pos = match.start(1)\n",
        "        end_pos = match.end(1)+1\n",
        "        #print(f\"Found '{matched_word}' at positions ({start_pos}, {end_pos})\")\n",
        "\n",
        "        predictions[id][\"NEG\"].add((start_pos,end_pos,matched_word))\n",
        "\n",
        "        # # Get the scope word\n",
        "        scope_word = match.group(2)\n",
        "        sc_start_pos = end_pos\n",
        "        sc_end_pos = match.end(2)+1\n",
        "\n",
        "        predictions[id][\"NSCO\"].add((sc_start_pos,sc_end_pos,scope_word))\n",
        "\n",
        "        #print(f\"Found scope '{scope_word}' at positions ({sc_start_pos}, {sc_end_pos})\")\n",
        "  '''\n",
        "  if neg_scopes_pos_matches:\n",
        "    for match in neg_scopes_pos_matches:\n",
        "        #print(\"Whole match:\", match.group(0))\n",
        "        # Get the matched word and its starting/ending positions\n",
        "        scope_word = match.group(1)\n",
        "        sc_start_pos = match.start()\n",
        "        sc_end_pos = match.end(1)+1\n",
        "\n",
        "\n",
        "       #print(f\"Found '{scope_word}' at positions ({sc_start_pos}, {sc_end_pos})\")\n",
        "        # # Get the scope word\n",
        "        matched_word = match.group(2)\n",
        "        start_pos = sc_end_pos\n",
        "        end_pos = match.end(2)+1\n",
        "\n",
        "\n",
        "        predictions[id][\"NEG\"].add((start_pos,end_pos,matched_word))\n",
        "        predictions[id][\"NSCO\"].add((sc_start_pos,sc_end_pos,scope_word))\n",
        "\n",
        "        #print(f\"Found scope '{match_word}' at positions ({start_pos}, {end_pos})\")\n",
        "  '''\n",
        "  if unc_scopes_pre_matches:\n",
        "    for match in unc_scopes_pre_matches:\n",
        "        #print(\"Whole match:\", match.group(0))\n",
        "        # Get the matched word and its starting/ending positions\n",
        "        matched_word = match.group(1)\n",
        "        start_pos = match.start()\n",
        "        end_pos = match.end(1)+1\n",
        "        #print(f\"Found '{matched_word}' at positions ({start_pos}, {end_pos})\")\n",
        "\n",
        "        predictions[id][\"UNC\"].add((start_pos,end_pos,matched_word))\n",
        "\n",
        "\n",
        "        # # Get the scope word\n",
        "        scope_word = match.group(2)\n",
        "        sc_start_pos = end_pos\n",
        "        sc_end_pos = match.end(2)+1\n",
        "        #print(f\"Found scope '{scope_word}' at positions ({sc_start_pos}, {sc_end_pos})\")\n",
        "\n",
        "        predictions[id][\"USCO\"].add((sc_start_pos,sc_end_pos,scope_word))\n",
        "    '''\n",
        "    if unc_scopes_pos_matches:\n",
        "      for match in unc_scopes_pos_matches:\n",
        "          #print(\"Whole match:\", match.group(0))\n",
        "          # Get the matched word and its starting/ending positions\n",
        "          scope_word = match.group(1)\n",
        "          sc_start_pos = match.start()\n",
        "          sc_end_pos = match.end(1)+1\n",
        "          #print(f\"Found '{scope_word}' at positions ({sc_start_pos}, {sc_end_pos})\")\n",
        "          # # Get the scope word\n",
        "          matched_word = match.group(2)\n",
        "          start_pos = sc_end_pos\n",
        "          end_pos = match.end(2)+1\n",
        "          #print(f\"Found scope '{matched_word}' at positions ({start_pos}, {end_pos})\")\n",
        "\n",
        "          predictions[id][\"UNC\"].add((start_pos,end_pos,matched_word))\n",
        "          predictions[id][\"USCO\"].add((sc_start_pos,sc_end_pos,scope_word))\n",
        "    '''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIXFSiPV_n-5"
      },
      "source": [
        "Sort the text predictions by starting point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "kP9PXuiBy5xA"
      },
      "outputs": [],
      "source": [
        "for dict in predictions:\n",
        "    for key,value in dict.items():\n",
        "\n",
        "      sorted_value=sorted(list(value), key=lambda x: x[0])\n",
        "      dict[key] = sorted_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20kWSstUYBox",
        "outputId": "c3ff1761-8cf1-4241-d278-eff5cee2255c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'NEG': [(395, 398, 'no'), (1111, 1120, 'negativo'), (1141, 1144, 'no'), (1313, 1322, 'negativo'), (2118, 2122, 'sin')], 'NSCO': [(398, 563, 'alergias medicamentosas conocidas antcededentes medico-quirurgicos: protesis mamaria, adenoidectomia niega habitos toxicos medicacio habitual anafranil25 mg/ diario'), (1120, 1120, ''), (1144, 1204, 'inmune, toxoplasma no immune, lues vih, vhb y vhc negativos'), (1322, 1346, '- eco 1ยบ t: crl:60 tn:1'), (2122, 2134, 'incidencias')], 'UNC': [(3460, 3466, 'puede')], 'USCO': [(3466, 3537, 'alternarse cada 4 horas con 1 comprimido de ibuprofeno 600mg si dolor)')]}\n"
          ]
        }
      ],
      "source": [
        "print(predictions[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tKQTkf9_xsz"
      },
      "source": [
        "Get ground thruth from testing_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "nsXxzCX3FXB7"
      },
      "outputs": [],
      "source": [
        "def get_gt_format(document):\n",
        "    neg_predictions, unc_predictions, nsco_predictions, usco_predictions = [], [], [], []\n",
        "    text = document[\"data\"][\"text\"]\n",
        "    for result_element in document[\"predictions\"][0][\"result\"]:\n",
        "        start = result_element[\"value\"][\"start\"]\n",
        "        end = result_element[\"value\"][\"end\"]\n",
        "        if \"NEG\" in result_element[\"value\"][\"labels\"]:\n",
        "            neg_predictions.append((start, end, text[start:end]))\n",
        "        if \"UNC\" in result_element[\"value\"][\"labels\"]:\n",
        "            unc_predictions.append((start, end, text[start:end]))\n",
        "        if \"NSCO\" in result_element[\"value\"][\"labels\"]:\n",
        "            nsco_predictions.append((start, end, text[start:end]))\n",
        "        if \"USCO\" in result_element[\"value\"][\"labels\"]:\n",
        "            usco_predictions.append((start, end, text[start:end]))\n",
        "\n",
        "    return neg_predictions, unc_predictions, nsco_predictions, usco_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GD-QWt5ZE3-D",
        "outputId": "0e0e424d-73f4-40b2-b5b4-870ad9cd327b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'NEG': [(395, 398, 'no '),\n",
              "  (499, 505, 'niega '),\n",
              "  (1111, 1119, 'negativo'),\n",
              "  (1141, 1144, 'no '),\n",
              "  (1163, 1166, 'no '),\n",
              "  (1194, 1203, 'negativos'),\n",
              "  (2118, 2122, 'sin ')],\n",
              " 'UNC': [],\n",
              " 'NSCO': [(398, 422, 'alergias medicamentosas '),\n",
              "  (505, 521, 'habitos toxicos '),\n",
              "  (1107, 1111, 'vih '),\n",
              "  (1144, 1150, 'inmune'),\n",
              "  (1166, 1172, 'immune'),\n",
              "  (1174, 1194, 'lues vih, vhb y vhc '),\n",
              "  (2122, 2133, 'incidencias')],\n",
              " 'USCO': []}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# FORMAT : (NEG, START, END, WORD)\n",
        "def get_ground_truth(document):\n",
        "    neg_results, unc_results, nsco_results, usco_results = get_gt_format(document)\n",
        "\n",
        "    neg_results_sorted = sorted(neg_results, key=lambda x: x[0])\n",
        "    unc_results_sorted = sorted(unc_results, key=lambda x: x[0])\n",
        "    nsco_results_sorted = sorted(nsco_results, key=lambda x: x[0])\n",
        "    usco_results_sorted = sorted(usco_results, key=lambda x: x[0])\n",
        "\n",
        "    ground_truth_dict = {\"NEG\": neg_results_sorted, \"UNC\": unc_results_sorted, \"NSCO\": nsco_results_sorted, \"USCO\": usco_results_sorted}\n",
        "\n",
        "    return ground_truth_dict\n",
        "\n",
        "\n",
        "\n",
        "get_ground_truth(testing_set[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "a9yh7F-jE6tU"
      },
      "outputs": [],
      "source": [
        "# List of dictionaries of GT docuemnts in the test set\n",
        "ground_truths = [get_ground_truth(document) for document in testing_set]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh9oGSB2Bcii"
      },
      "source": [
        "Calculate Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "x8dBo8oiF8Ho"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(predictions,ground_truths):\n",
        "  precision = {\"NEG\":0,\"NSCO\":0,\"UNC\":0,\"USCO\":0}\n",
        "  recall = {\"NEG\":0,\"NSCO\":0,\"UNC\":0,\"USCO\":0}\n",
        "  f1 = {\"NEG\":0,\"NSCO\":0,\"UNC\":0,\"USCO\":0}\n",
        "  tp = {\"NEG\":0,\"NSCO\":0,\"UNC\":0,\"USCO\":0}\n",
        "  num_of_predictions = {\"NEG\":0,\"NSCO\":0,\"UNC\":0,\"USCO\":0}\n",
        "  num_of_ground_truths = {\"NEG\":0,\"NSCO\":0,\"UNC\":0,\"USCO\":0}\n",
        "  for d1,d2 in zip(predictions,ground_truths):\n",
        "\n",
        "    #print(d1[\"UNC\"])\n",
        "    #print(d2[\"UNC\"])\n",
        "    for key in d1:\n",
        "      #print(key)\n",
        "      for elem in d1[key]:\n",
        "        for elem2 in d2[key]:\n",
        "          if abs(elem[0]-elem2[0]) <= 1 and abs(elem[1]-elem2[1]) <=1:\n",
        "            tp[key]+=1\n",
        "            break\n",
        "\n",
        "      num_of_predictions[key]+=len(d1[key])\n",
        "      num_of_ground_truths[key]+=len(d2[key])\n",
        "\n",
        "  for key in precision:\n",
        "    precision[key] = tp[key]/num_of_predictions[key]\n",
        "    recall[key] = tp[key]/num_of_ground_truths[key]\n",
        "    f1[key] = 2*precision[key]*recall[key]/(precision[key]+recall[key])\n",
        "\n",
        "\n",
        "  return precision, recall, f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "ugryzw7-z1T6"
      },
      "outputs": [],
      "source": [
        "precision, recall, f1 = calculate_metrics(predictions,ground_truths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmuaHq_92t7e"
      },
      "source": [
        "Baseline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKJflAwl2wpl",
        "outputId": "77c7d3e8-2fdc-4271-a4a3-821e33367790"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'NEG': 0.924812030075188, 'NSCO': 0.5366541353383458, 'UNC': 0.5963855421686747, 'USCO': 0.15060240963855423}\n",
            "{'NEG': 0.8692579505300353, 'NSCO': 0.5316573556797021, 'UNC': 0.7557251908396947, 'USCO': 0.1937984496124031}\n",
            "{'NEG': 0.8961748633879781, 'NSCO': 0.5341440598690365, 'UNC': 0.6666666666666667, 'USCO': 0.16949152542372883}\n"
          ]
        }
      ],
      "source": [
        "print(precision)\n",
        "print(recall)\n",
        "print(f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiqTWLBOGVkt"
      },
      "source": [
        "CUTEXT\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvBibqG3Ga_9",
        "outputId": "e289e0c7-ca67-406e-80d1-4dc72cf1f3ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'NEG': 0.9217148182665424, 'NSCO': 0.17054986020503263, 'UNC': 0.5857988165680473, 'USCO': 0.08284023668639054}\n",
            "{'NEG': 0.8736749116607774, 'NSCO': 0.17039106145251395, 'UNC': 0.7557251908396947, 'USCO': 0.10852713178294573}\n",
            "{'NEG': 0.8970521541950113, 'NSCO': 0.17047042384722869, 'UNC': 0.66, 'USCO': 0.09395973154362416}\n"
          ]
        }
      ],
      "source": [
        "print(precision)\n",
        "print(recall)\n",
        "print(f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vm3g-nDobLJ"
      },
      "source": [
        "CUTEXT + Scope_words REGEX 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-9fgOyLAJJe",
        "outputId": "0d77cce8-b0a7-4d99-87d9-d112c49b5705"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'NEG': 0.924314096499527, 'NSCO': 0.5799432355723746, 'UNC': 0.5963855421686747, 'USCO': 0.22289156626506024}\n",
            "{'NEG': 0.8630742049469965, 'NSCO': 0.5707635009310987, 'UNC': 0.7557251908396947, 'USCO': 0.2868217054263566}\n",
            "{'NEG': 0.8926450433988123, 'NSCO': 0.5753167526982637, 'UNC': 0.6666666666666667, 'USCO': 0.2508474576271187}\n"
          ]
        }
      ],
      "source": [
        "print(precision)\n",
        "print(recall)\n",
        "print(f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkOW3RAuo00q"
      },
      "source": [
        "CUTEXT + Scope_words REGEX 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 309,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vV3QoBIEv04",
        "outputId": "48839acf-78bd-4375-8a25-324e84a4ca91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'NEG': 0.9249578414839797, 'NSCO': 0.5168634064080945, 'UNC': 0.5706214689265536, 'USCO': 0.20903954802259886}\n",
            "{'NEG': 0.9690812720848057, 'NSCO': 0.5707635009310987, 'UNC': 0.7709923664122137, 'USCO': 0.2868217054263566}\n",
            "{'NEG': 0.9465056082830027, 'NSCO': 0.5424778761061947, 'UNC': 0.6558441558441559, 'USCO': 0.2418300653594771}\n"
          ]
        }
      ],
      "source": [
        "print(precision)\n",
        "print(recall)\n",
        "print(f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Until the end of the proposition\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'NEG': 0.9134615384615384, 'NSCO': 0.55, 'UNC': 0.6329113924050633, 'USCO': 0.3227848101265823}\n",
            "{'NEG': 0.8392226148409894, 'NSCO': 0.5325884543761639, 'UNC': 0.7633587786259542, 'USCO': 0.3953488372093023}\n",
            "{'NEG': 0.874769797421731, 'NSCO': 0.5411542100283822, 'UNC': 0.6920415224913494, 'USCO': 0.3554006968641115}\n"
          ]
        }
      ],
      "source": [
        "print(precision)\n",
        "print(recall)\n",
        "print(f1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
